---
title: A Poorly Named Tool for Estimating the Performance and Power of Deep Learning Accelerators
---
My group is working on a project that collides with research on hardware accelerators for deep neural networks. We're not actually building a new accelerator, but we need to know roughly how one behaves.

Despite this area's face-melting hotness, it has not generated many reusable research tools.
TK link to Eyeriss web tool and NVDLA.
TK we emailed lots of people.

There's an analogy to be made to research on CPUs or GPUs.
TK links to McPAT, etc.
Some people argue that deep learning accelerators will soon be as commonplace as those more traditional units---and while it's not a foregone conclusion, it is a plausible argument.
TK branch predictor analogy: it would be crazy if every predictor needed to design a whole core to go around it.

TK if CNN accelerators are going to be as commonplace, we need common infrastructrure. a baseline of agreement.
TK importance of standardization, even on imperfect tools.
